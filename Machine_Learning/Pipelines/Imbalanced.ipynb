{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3c8c5c5f2f6bc7ab03bb842ddffdfb34ea87607c"
   },
   "source": [
    "# Methods for Dealing with Imbalanced Data\n",
    "Imbalanced classes are a common problem in machine learning classification where there are a disproportionate ratio of observations in each class.  Class imbalance can be found in many different areas including medical diagnosis, spam filtering, and fraud detection.\n",
    "\n",
    "In this guide, we'll look at five possible ways to handle an imbalanced class problem using credit card data.  Our objective will be to correctly classify the minority class of fraudulent transactions.\n",
    "\n",
    "Important Note:\n",
    "This guide will focus soley on addressing imbalanced classes and will not addressing other important machine learning steps including, but not limited to, feature selection or hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#import n\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, recall_score\n",
    "\n",
    "# setting up default plotting parameters\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20.0, 7.0]\n",
    "plt.rcParams.update({'font.size': 22,})\n",
    "\n",
    "sns.set_palette('viridis')\n",
    "sns.set_style('white')\n",
    "sns.set_context('talk', font_scale=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, r2_score, accuracy_score, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, RidgeCV, Ridge, lars_path\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "\n",
    "#from xgboost import XGBClassifier, XGBRegressor\n",
    "#from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "#from catboost import CatBoostRegressor\n",
    "\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.feature_selection import RFE\n",
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/creditcard.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/s2/b8br99sx37j63cwmqyrwzz2w0000gn/T/ipykernel_1171/1300027827.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/creditcard.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Resampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 0. Split the data before resampling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    702\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/creditcard.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/creditcard.csv\")\n",
    "#######################\n",
    "# Resampling \n",
    "# 0. Split the data before resampling\n",
    "y = df['Class']\n",
    "X = df.drop(columns=['Class'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# 1. Create df_train=(X_train, y_train) and define frauds and nonfrauds\n",
    "df_train=X = pd.concat([X_train, y_train], axis=1)\n",
    "fraud= df_train[df_train['Class']==1]\n",
    "nonfraud= df_train[df_train['Class']==0]\n",
    "\n",
    "# 2. Take n (=nonfrauds'numbers) samples from the frauds and get X_train and y_train\n",
    "fraud_up = resample(fraud, replace=True, n_samples=len(nonfraud)) \n",
    "df_up = pd.concat([fraud_up, nonfraud])\n",
    "y_train = df_up['Class']\n",
    "X_train = df_up.drop(columns=['Class'])\n",
    "\n",
    "# 3. Train and test a classifier...\n",
    "\n",
    "####################################################################################\n",
    "# SMOTE \n",
    "# 0. Split the data before resampling\n",
    "y = df['Class']\n",
    "X = df.drop(columns=['Class'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# 1. Create X_train, y_train directly via SMOTE \n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=27)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# 2. Train and test a classifier..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "df = pd.read_csv('../data/creditcard.csv')\n",
    "print(df.Class.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "00001b711204cdcfe0a91021db7197bb81e1b6b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omid/opt/anaconda3/lib/python3.8/site-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# using seaborns countplot to show distribution of questions in dataset\n",
    "fig, ax = plt.subplots()\n",
    "g = sns.countplot(df.Class, palette='viridis')\n",
    "g.set_xticklabels(['Not Fraud', 'Fraud'])\n",
    "g.set_yticklabels([])\n",
    "\n",
    "# function to show values on bars\n",
    "def show_values_on_bars(axs):\n",
    "    def _show_on_single_plot(ax):        \n",
    "        for p in ax.patches:\n",
    "            _x = p.get_x() + p.get_width() / 2\n",
    "            _y = p.get_y() + p.get_height()\n",
    "            value = '{:.0f}'.format(p.get_height())\n",
    "            ax.text(_x, _y, value, ha=\"center\") \n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _show_on_single_plot(ax)\n",
    "    else:\n",
    "        _show_on_single_plot(axs)\n",
    "show_values_on_bars(ax)\n",
    "\n",
    "sns.despine(left=True, bottom=True)\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.title('Distribution of Transactions', fontsize=30)\n",
    "plt.tick_params(axis='x', which='major', labelsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a22d03aa7bf5b358cfbc7ca946f3367b98e9faa2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17304750013189596"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print percentage of questions where target == 1\n",
    "(len(df.loc[df.Class==1])) / (len(df.loc[df.Class == 0])) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "460b8fbc891a865d755de263e832474d22718577"
   },
   "source": [
    "From the plot above, we can see we have a very imbalanced class -  just 0.17% of our dataset belong to the target class!\n",
    "\n",
    "This is a problem because many machine learning models are designed to maximize overall accuracy, which especially with imbalanced classes may not be the best metric to use. Classification accuracy is defined as the number of correct predictions divided by total predictions times 100. For example, if we simply predicted all transactions are not fraud, we would get a classification acuracy score of over 99%!\n",
    "\n",
    "### Create Train and Test Sets\n",
    "\n",
    "The training set is used to build and validate the model, while the test set is reserved for testing the model on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "876d7f98c708ae91ce22f728d63abdbb1c573fac"
   },
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "# Separate input features and target\n",
    "y = df.Class\n",
    "X = df.drop('Class', axis=1)\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5b635aecad2e3a59eee638e62194f02855f4f8f"
   },
   "source": [
    "## Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "537af7e533e55efc91ecda7a6f80b4c88bac39a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted labels:  [0]\n",
      "Test score:  0.9981461194910255\n"
     ]
    }
   ],
   "source": [
    "# DummyClassifier to predict only target 0\n",
    "dummy = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "dummy_pred = dummy.predict(X_test)\n",
    "\n",
    "# checking unique labels\n",
    "print('Unique predicted labels: ', (np.unique(dummy_pred)))\n",
    "\n",
    "# checking accuracy\n",
    "print('Test score: ', accuracy_score(y_test, dummy_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b3d37e60424e9bc6a0ffdf36bc667a7489ce186"
   },
   "source": [
    "As predicted our accuracy score for classifying all transactions as not fraud is 99.8%!  \n",
    "\n",
    "As the Dummy Classifier predicts only Class 0, it is clearly not a good option for our objective of correctly classifying fraudulent transactions.\n",
    "\n",
    "Let's see how logistic regression performs on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "3326dfa795f14d1f4357881c3dde02f84b5574dd"
   },
   "outputs": [],
   "source": [
    "# Modeling the data as is\n",
    "# Train model\n",
    "lr = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    " \n",
    "# Predict on training set\n",
    "lr_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "df5a5a9588b0d0ee1d9b80e94d1c63885718976d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991994606893064"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking accuracy\n",
    "accuracy_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "64afcae23af7b0903f10fa0d2992de3a137e2c10"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    71109\n",
       "1       93\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique values\n",
    "predictions = pd.DataFrame(lr_pred)\n",
    "predictions[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f50e9de7d0b21afebbdf41c36e30a3dd7e4204e0"
   },
   "source": [
    "Logistic Regression outperformed the Dummy Classifier!  We can see that it predicted 94 instances of class 1, so this is definitely an improvement.  But can we do better?\n",
    "\n",
    "Let's see if we can apply some techniques for dealing with class imbalance to improve these results.\n",
    "\n",
    "## 1.  Change the performance metric\n",
    "Accuracy is not the best metric to use when evaluating imbalanced datasets as it can be misleading.  Metrics that can provide better insight include:\n",
    " - **Confusion Matrix:**  a talbe showing correct predictions and types of incorrect predictions.\n",
    " - **Precision: **  the number of true positives divided by all positive predictions. Precision is also called Positive Predictive Value. It is a measure of a classifier's exactness. Low precision indicates a high number of false positives.\n",
    " - **Recall:**  the number of true positives divided by the number of positive values in the test data. Recall is also called Sensitivity or the True Positive Rate. It is a measure of a classifier's completeness. Low recall indicates a high number of false negatives.\n",
    " - **F1: Score:**  the weighted average of precision and recall.\n",
    " \n",
    "Since our main objective with the dataset is to prioritize accuraltely classifying fraud cases the recall score can be considered our main metric to use for evaluating outcomes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "eccc36a7bfcea78426978634b710cc0133a38806"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7466666666666666"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "f1_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "e45f328fd05fff579301f2f060d6e8412b0c50c2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71061</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0   1\n",
       "0  71061   9\n",
       "1     48  84"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "0e1e8e7a188457a84e07f11f1789d7b864b5bef8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dffefb9a7656b70369b1392747345f1b7c5ad830",
    "collapsed": true
   },
   "source": [
    "We have a very high accuracy score of 0.999 but a F1 score of only 0.752.  And from the confusion matrix, we can see we are misclassifying several observations leading to a recall score of only 0.64.\n",
    "\n",
    "## 2. Change the algorithm\n",
    "While in every machine learning problem, its a good rule of thumb to try a variety of algorithms, it can be especially beneficial with imbalanced datasets.  Decision trees frequently perform well on imbalanced data.  They work by learning a hierachy of if/else questions.  This can force both classes to be addressed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "aa114a52def766752d99bdbb8798926b08bfa7c0"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "f12b26ae5dd82aac3a909dba0346055d0e9162b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9995365298727564"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "rfc = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)\n",
    "\n",
    "# predict on test set\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "88a80554fe0898f9a7b4a129e72bd08e3a2b0e23"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8595744680851064"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "f1_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "48bbc426053a07d88363c8207254b8c60cd97fdf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71068</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  71068    2\n",
       "1     31  101"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "0d2fe2f258a7f3a2db17b963b76116f00fa5c1f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7651515151515151"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall score\n",
    "recall_score(y_test, rfc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "adead2ec74b7016ebc547ee60e0b44dc1189a2a4"
   },
   "source": [
    "# Resampling Techniques\n",
    "\n",
    "## 3. Oversampling Minority Class\n",
    "Oversampling can be defined as adding more copies of the minority class.  Oversampling can be a good choice when you don't have a ton of data to work with.  A con to consider when undersampling is that it can cause overfitting and poor generalization to your test set.\n",
    "\n",
    "We will use the resampling module from Scikit-Learn to randomly replicate samples from the minority class.\n",
    "\n",
    "### **Important Note**\n",
    "Always split into test and train sets BEFORE trying any resampling techniques!  Oversampling before splitting the data can allow the exact same observations to be present in both the test and train sets!  This can allow our model to simply memorize specific data points and cause overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "_uuid": "e48e7eb85c4b0a67c3f096726fef7b472e6b293d"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79525</th>\n",
       "      <td>58060.0</td>\n",
       "      <td>-2.630598</td>\n",
       "      <td>5.125759</td>\n",
       "      <td>-6.092255</td>\n",
       "      <td>5.527393</td>\n",
       "      <td>1.605145</td>\n",
       "      <td>-2.319884</td>\n",
       "      <td>-3.207076</td>\n",
       "      <td>-1.482583</td>\n",
       "      <td>-5.074871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.527474</td>\n",
       "      <td>0.220546</td>\n",
       "      <td>-1.371110</td>\n",
       "      <td>-0.504899</td>\n",
       "      <td>0.382307</td>\n",
       "      <td>0.395528</td>\n",
       "      <td>0.782036</td>\n",
       "      <td>0.628528</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53591</th>\n",
       "      <td>46057.0</td>\n",
       "      <td>-1.309441</td>\n",
       "      <td>1.786495</td>\n",
       "      <td>-1.371070</td>\n",
       "      <td>1.214335</td>\n",
       "      <td>-0.336642</td>\n",
       "      <td>-1.390120</td>\n",
       "      <td>-1.709109</td>\n",
       "      <td>0.667748</td>\n",
       "      <td>-1.699809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533521</td>\n",
       "      <td>-0.022180</td>\n",
       "      <td>-0.299556</td>\n",
       "      <td>-0.226416</td>\n",
       "      <td>0.364360</td>\n",
       "      <td>-0.475102</td>\n",
       "      <td>0.571426</td>\n",
       "      <td>0.293426</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219025</th>\n",
       "      <td>141565.0</td>\n",
       "      <td>0.114965</td>\n",
       "      <td>0.766762</td>\n",
       "      <td>-0.494132</td>\n",
       "      <td>0.116772</td>\n",
       "      <td>0.868169</td>\n",
       "      <td>-0.477982</td>\n",
       "      <td>0.438496</td>\n",
       "      <td>0.063073</td>\n",
       "      <td>-0.186207</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284413</td>\n",
       "      <td>-0.706865</td>\n",
       "      <td>0.131405</td>\n",
       "      <td>0.600742</td>\n",
       "      <td>-0.604264</td>\n",
       "      <td>0.262938</td>\n",
       "      <td>0.099145</td>\n",
       "      <td>0.010810</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239501</th>\n",
       "      <td>150139.0</td>\n",
       "      <td>-6.682832</td>\n",
       "      <td>-2.714268</td>\n",
       "      <td>-5.774530</td>\n",
       "      <td>1.449792</td>\n",
       "      <td>-0.661836</td>\n",
       "      <td>-1.148650</td>\n",
       "      <td>0.849686</td>\n",
       "      <td>0.433427</td>\n",
       "      <td>-1.315646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220526</td>\n",
       "      <td>1.187013</td>\n",
       "      <td>0.335821</td>\n",
       "      <td>0.215683</td>\n",
       "      <td>0.803110</td>\n",
       "      <td>0.044033</td>\n",
       "      <td>-0.054988</td>\n",
       "      <td>0.082337</td>\n",
       "      <td>237.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15204</th>\n",
       "      <td>26556.0</td>\n",
       "      <td>-19.179826</td>\n",
       "      <td>11.817922</td>\n",
       "      <td>-21.919174</td>\n",
       "      <td>6.086236</td>\n",
       "      <td>-14.708845</td>\n",
       "      <td>-4.308888</td>\n",
       "      <td>-15.357952</td>\n",
       "      <td>12.857165</td>\n",
       "      <td>-3.999861</td>\n",
       "      <td>...</td>\n",
       "      <td>1.746802</td>\n",
       "      <td>-1.353149</td>\n",
       "      <td>-0.762965</td>\n",
       "      <td>0.117028</td>\n",
       "      <td>1.297994</td>\n",
       "      <td>-0.224825</td>\n",
       "      <td>1.621052</td>\n",
       "      <td>0.484614</td>\n",
       "      <td>99.99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150925</th>\n",
       "      <td>94141.0</td>\n",
       "      <td>-13.512074</td>\n",
       "      <td>8.215177</td>\n",
       "      <td>-16.582606</td>\n",
       "      <td>6.207369</td>\n",
       "      <td>-11.318472</td>\n",
       "      <td>-2.997207</td>\n",
       "      <td>-17.640470</td>\n",
       "      <td>0.040349</td>\n",
       "      <td>-5.620232</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.907906</td>\n",
       "      <td>1.514028</td>\n",
       "      <td>-0.141879</td>\n",
       "      <td>0.789186</td>\n",
       "      <td>-0.031343</td>\n",
       "      <td>-0.255057</td>\n",
       "      <td>-1.865831</td>\n",
       "      <td>-0.442204</td>\n",
       "      <td>45.48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107637</th>\n",
       "      <td>70536.0</td>\n",
       "      <td>-2.271755</td>\n",
       "      <td>-0.457655</td>\n",
       "      <td>-2.589055</td>\n",
       "      <td>2.230778</td>\n",
       "      <td>-4.278983</td>\n",
       "      <td>0.388610</td>\n",
       "      <td>0.102485</td>\n",
       "      <td>0.813128</td>\n",
       "      <td>-1.092921</td>\n",
       "      <td>...</td>\n",
       "      <td>1.096342</td>\n",
       "      <td>0.658399</td>\n",
       "      <td>1.711676</td>\n",
       "      <td>0.333540</td>\n",
       "      <td>0.538591</td>\n",
       "      <td>-0.193529</td>\n",
       "      <td>0.258194</td>\n",
       "      <td>0.247269</td>\n",
       "      <td>824.83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143731</th>\n",
       "      <td>85576.0</td>\n",
       "      <td>-2.207631</td>\n",
       "      <td>3.259076</td>\n",
       "      <td>-5.436365</td>\n",
       "      <td>3.684737</td>\n",
       "      <td>-3.066401</td>\n",
       "      <td>-0.671323</td>\n",
       "      <td>-3.696178</td>\n",
       "      <td>1.822272</td>\n",
       "      <td>-3.049653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.920899</td>\n",
       "      <td>0.037675</td>\n",
       "      <td>0.026754</td>\n",
       "      <td>-0.791489</td>\n",
       "      <td>0.176493</td>\n",
       "      <td>-0.136312</td>\n",
       "      <td>1.087585</td>\n",
       "      <td>0.373834</td>\n",
       "      <td>240.77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76555</th>\n",
       "      <td>56624.0</td>\n",
       "      <td>-7.901421</td>\n",
       "      <td>2.720472</td>\n",
       "      <td>-7.885936</td>\n",
       "      <td>6.348334</td>\n",
       "      <td>-5.480119</td>\n",
       "      <td>-0.333059</td>\n",
       "      <td>-8.682376</td>\n",
       "      <td>1.164431</td>\n",
       "      <td>-4.542447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077739</td>\n",
       "      <td>1.092437</td>\n",
       "      <td>0.320133</td>\n",
       "      <td>-0.434643</td>\n",
       "      <td>-0.380687</td>\n",
       "      <td>0.213630</td>\n",
       "      <td>0.423620</td>\n",
       "      <td>-0.105169</td>\n",
       "      <td>153.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11343</th>\n",
       "      <td>19762.0</td>\n",
       "      <td>-14.179165</td>\n",
       "      <td>7.421370</td>\n",
       "      <td>-21.405836</td>\n",
       "      <td>11.927512</td>\n",
       "      <td>-7.974281</td>\n",
       "      <td>-2.202710</td>\n",
       "      <td>-15.471612</td>\n",
       "      <td>-0.356595</td>\n",
       "      <td>-6.380125</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.366836</td>\n",
       "      <td>1.130955</td>\n",
       "      <td>0.991153</td>\n",
       "      <td>-1.033132</td>\n",
       "      <td>-0.327179</td>\n",
       "      <td>0.634693</td>\n",
       "      <td>2.171905</td>\n",
       "      <td>-1.395288</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2         V3         V4         V5  \\\n",
       "79525    58060.0  -2.630598   5.125759  -6.092255   5.527393   1.605145   \n",
       "53591    46057.0  -1.309441   1.786495  -1.371070   1.214335  -0.336642   \n",
       "219025  141565.0   0.114965   0.766762  -0.494132   0.116772   0.868169   \n",
       "239501  150139.0  -6.682832  -2.714268  -5.774530   1.449792  -0.661836   \n",
       "15204    26556.0 -19.179826  11.817922 -21.919174   6.086236 -14.708845   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "150925   94141.0 -13.512074   8.215177 -16.582606   6.207369 -11.318472   \n",
       "107637   70536.0  -2.271755  -0.457655  -2.589055   2.230778  -4.278983   \n",
       "143731   85576.0  -2.207631   3.259076  -5.436365   3.684737  -3.066401   \n",
       "76555    56624.0  -7.901421   2.720472  -7.885936   6.348334  -5.480119   \n",
       "11343    19762.0 -14.179165   7.421370 -21.405836  11.927512  -7.974281   \n",
       "\n",
       "              V6         V7         V8        V9  ...       V21       V22  \\\n",
       "79525  -2.319884  -3.207076  -1.482583 -5.074871  ... -0.527474  0.220546   \n",
       "53591  -1.390120  -1.709109   0.667748 -1.699809  ...  0.533521 -0.022180   \n",
       "219025 -0.477982   0.438496   0.063073 -0.186207  ... -0.284413 -0.706865   \n",
       "239501 -1.148650   0.849686   0.433427 -1.315646  ...  0.220526  1.187013   \n",
       "15204  -4.308888 -15.357952  12.857165 -3.999861  ...  1.746802 -1.353149   \n",
       "...          ...        ...        ...       ...  ...       ...       ...   \n",
       "150925 -2.997207 -17.640470   0.040349 -5.620232  ... -0.907906  1.514028   \n",
       "107637  0.388610   0.102485   0.813128 -1.092921  ...  1.096342  0.658399   \n",
       "143731 -0.671323  -3.696178   1.822272 -3.049653  ...  0.920899  0.037675   \n",
       "76555  -0.333059  -8.682376   1.164431 -4.542447  ...  0.077739  1.092437   \n",
       "11343  -2.202710 -15.471612  -0.356595 -6.380125  ... -2.366836  1.130955   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "79525  -1.371110 -0.504899  0.382307  0.395528  0.782036  0.628528    1.00   \n",
       "53591  -0.299556 -0.226416  0.364360 -0.475102  0.571426  0.293426    1.00   \n",
       "219025  0.131405  0.600742 -0.604264  0.262938  0.099145  0.010810    4.49   \n",
       "239501  0.335821  0.215683  0.803110  0.044033 -0.054988  0.082337  237.26   \n",
       "15204  -0.762965  0.117028  1.297994 -0.224825  1.621052  0.484614   99.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "150925 -0.141879  0.789186 -0.031343 -0.255057 -1.865831 -0.442204   45.48   \n",
       "107637  1.711676  0.333540  0.538591 -0.193529  0.258194  0.247269  824.83   \n",
       "143731  0.026754 -0.791489  0.176493 -0.136312  1.087585  0.373834  240.77   \n",
       "76555   0.320133 -0.434643 -0.380687  0.213630  0.423620 -0.105169  153.46   \n",
       "11343   0.991153 -1.033132 -0.327179  0.634693  2.171905 -1.395288    1.00   \n",
       "\n",
       "        Class  \n",
       "79525       1  \n",
       "53591       1  \n",
       "219025      1  \n",
       "239501      1  \n",
       "15204       1  \n",
       "...       ...  \n",
       "150925      1  \n",
       "107637      1  \n",
       "143731      1  \n",
       "76555       1  \n",
       "11343       1  \n",
       "\n",
       "[360 rows x 31 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()\n",
    "\n",
    "fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "_uuid": "8d7567a5b4ebc92b3aaff6236f2253d969488993"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69710</td>\n",
       "      <td>1360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  69710  1360\n",
       "1     18   114"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/creditcard.csv')\n",
    "# Separate input features and target\n",
    "y = df['Class']\n",
    "X = df.drop(columns=['Class'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
    "\n",
    "# concatenate our training data back together\n",
    "X = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# separate minority and majority classes\n",
    "not_fraud = X[X.Class==0]\n",
    "fraud = X[X.Class==1]\n",
    "\n",
    "# upsample minority\n",
    "fraud_upsampled = resample(fraud,replace=True, n_samples=len(not_fraud)) \n",
    "\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([not_fraud, fraud_upsampled])\n",
    "\n",
    "# trying logistic regression again with the balanced dataset\n",
    "y_train = upsampled['Class']\n",
    "X_train = upsampled.drop(columns=['Class'])\n",
    "\n",
    "LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "upsampled_pred = upsampled.predict(X_test)\n",
    "pd.DataFrame(confusion_matrix(y_test, upsampled_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a0b5c7e2b673baac682bb89d9484ad9f7fbea16e"
   },
   "source": [
    "Our accuracy score decreased after upsampling, but the model is now predicting both classes more equally, making it an improvement over our plain logistic regression above.\n",
    "\n",
    "## 4. Undersampling Majority Class\n",
    "Undersampling can be defined as removing some observations of the majority class.  Undersampling can be a good choice when you have a ton of data -think millions of rows.  But a drawback to undersampling is that we are removing information that may be valuable.\n",
    "\n",
    "We will again use the resampling module from Scikit-Learn to randomly remove samples from the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "15c289c9551acca877a3ca824c6b2f074daccce6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    360\n",
       "0    360\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# still using our separated classes fraud and not_fraud from above\n",
    "\n",
    "# downsample majority\n",
    "not_fraud_downsampled = resample(not_fraud,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(fraud), # match minority n\n",
    "                                random_state = 27) # reproducible results\n",
    "\n",
    "# combine minority and downsampled majority\n",
    "downsampled = pd.concat([not_fraud_downsampled, fraud])\n",
    "\n",
    "# checking counts\n",
    "downsampled.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "339ff5f558175b8daf2a4536d4749978e7e7c4fd"
   },
   "outputs": [],
   "source": [
    "# trying logistic regression again with the undersampled dataset\n",
    "\n",
    "y_train = downsampled.Class\n",
    "X_train = downsampled.drop('Class', axis=1)\n",
    "\n",
    "undersampled = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "undersampled_pred = undersampled.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "a4808d815c2531edfbb93ad420a40bf2aa4c85f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9758574197354007"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking accuracy\n",
    "accuracy_score(y_test, undersampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "5f79a91effffd12bec83359230618af1c7ed23f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11710323574730355"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "f1_score(y_test, undersampled_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "9b8cab34cf1a0c10ca0f862909abbc83e35fbecd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69369</td>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1\n",
       "0  69369  1701\n",
       "1     18   114"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, undersampled_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "8240af095c11b2a48da1eeba3a75e70aa902610c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8636363636363636"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, undersampled_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0cdac5de057cf831e81f8766b539834accf46663"
   },
   "source": [
    "Downsampling produced a higher recall score than upsampling!  My concern here is the small number of total samples we used to train the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9ce5844e2d4447485416cf927112a8c2cf3fd1d8"
   },
   "source": [
    "## 5. Generate Synthetic Samples\n",
    "SMOTE or Synthetic Minority Oversampling Technique is a popular algorithm to creates sythetic observations of the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "5d01357038bb94f8a93c77141e462153c73c5ab8"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Separate input features and target\n",
    "y = df.Class\n",
    "X = df.drop('Class', axis=1)\n",
    "\n",
    "# setting up testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=27)\n",
    "\n",
    "sm = SMOTE(random_state=27)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "669cb81d0cf57aa6c3769a586253ac5e1e5622bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9858571388444145"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "smote_pred = smote.predict(X_test)\n",
    "\n",
    "# Checking accuracy\n",
    "accuracy_score(y_test, smote_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "a53ecb2ee29d381dbc4da8fc897242c37153b75e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18461538461538463"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "f1_score(y_test, smote_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "5be328bfd7f9661505264b65f085069e5de08b53"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70081</td>\n",
       "      <td>989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0  70081  989\n",
       "1     18  114"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confustion matrix\n",
    "pd.DataFrame(confusion_matrix(y_test, smote_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "991a2802f90abfc195f6f0325b77ba45efc9e404"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8636363636363636"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test, smote_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8bde53447fef057292a1d52b62978e53b7d44f8f"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "We covered 5 different methods for dealing with imbalanced datasets:\n",
    "1.  Change the performance metric\n",
    "2.  Oversampling minority class\n",
    "3.  Undersampling majority class\n",
    "4.  Change the algorithm\n",
    "5.  Generate synthetic samples\n",
    "\n",
    "These are just some of the many possible methods to try when dealing with imbalanced datasets, and not an exhaustive list.  Some others methods to consider are collecting more data or choosing different resampling ratios - you don't have to have exactly a 1:1 ratio!  You should always try several approaches and then decide which is best for your problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
