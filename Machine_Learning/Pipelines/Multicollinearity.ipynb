{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example One"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF can be computed for each regressor by fitting an OLS model that has the regressor in question as a target variable and all other regressors as features. VIF should be smaller than 5 (small datasets) or 10 (larger datasets).\n",
    "\n",
    "- droping of correlated regressors \n",
    "\n",
    "- PCA  \n",
    "\n",
    "- penalized regression methods e.g. ridge and lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>174</td>\n",
       "      <td>96</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>189</td>\n",
       "      <td>87</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>185</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>195</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>149</td>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Height  Weight  Index\n",
       "0    Male     174      96      4\n",
       "1    Male     189      87      2\n",
       "2  Female     185     110      4\n",
       "3  Female     195     104      3\n",
       "4    Male     149      61      3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# the dataset\n",
    "df = pd.read_csv('../data/BMI.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0288639241099915\n",
      "11.623103405710753\n",
      "10.688377415326789\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# dummy variable for gender\n",
    "df['Gender'] = df['Gender'].map({'Male':0, 'Female':1})\n",
    "\n",
    "X = df[['Gender', 'Height', 'Weight']]\n",
    "\n",
    "for i in range(len(X.columns)):\n",
    "    print (variance_inflation_factor(X.values, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Height and weight are highly correlated and only one of them should be considerd.\n",
    "\n",
    "variance_inflation_factor(exog, exog_idx)\n",
    "\n",
    "exog: an array containing features on which linear regression is performed.\n",
    "\n",
    "exog_idx: index of the additional feature whose influence on the other features is to be measured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/salary.csv')\n",
    "\n",
    "# handle missing values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2071549745904337\n",
      "13.706320280830282\n",
      "10.299486200207912\n",
      "2.4092629110214583\n"
     ]
    }
   ],
   "source": [
    "X=df[['Gender', 'Age', 'Years of service', 'Education level']] # Alternatively: X = df.iloc[:,:-1]\n",
    "\n",
    "for i in range(len(X.columns)):\n",
    "    print(variance_inflation_factor(X.values, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.168067939256931\n",
      "3.3269912119960123\n",
      "2.407695153124809\n"
     ]
    }
   ],
   "source": [
    "# Combining ‘Age’ and ‘Years of experience’ allows us to capture the information in both the variables.\n",
    "\n",
    "df_new = df.copy()\n",
    "df_new['Age_at_joining'] = df_new.apply(lambda x: x['Age'] - x['Years of service'],axis=1)\n",
    "\n",
    "X_new=df_new[['Gender', 'Age_at_joining', 'Education level']]\n",
    "\n",
    "for i in range(len(X_new.columns)):\n",
    "    print(variance_inflation_factor(X_new.values, i))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import boston dataset from sklearn\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "boston= load_boston()\n",
    "boston_features_df = pd.DataFrame(data=boston.data,columns=boston.feature_names)\n",
    "boston_target_df = pd.DataFrame(data=boston.target,columns=['MEDV'])\n",
    "\n",
    "X = boston_features_df\n",
    "Y = boston_target_df\n",
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X, Y, test_size = 0.20, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   MEDV   R-squared:                       0.738\n",
      "Model:                            OLS   Adj. R-squared:                  0.730\n",
      "Method:                 Least Squares   F-statistic:                     84.65\n",
      "Date:                Mon, 03 May 2021   Prob (F-statistic):          8.21e-105\n",
      "Time:                        21:01:03   Log-Likelihood:                -1202.0\n",
      "No. Observations:                 404   AIC:                             2432.\n",
      "Df Residuals:                     390   BIC:                             2488.\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         37.9125      5.775      6.565      0.000      26.559      49.266\n",
      "CRIM          -0.1308      0.036     -3.603      0.000      -0.202      -0.059\n",
      "ZN             0.0494      0.016      3.131      0.002       0.018       0.080\n",
      "INDUS          0.0011      0.072      0.015      0.988      -0.141       0.143\n",
      "CHAS           2.7054      0.989      2.737      0.006       0.762       4.649\n",
      "NOX          -15.9571      4.517     -3.532      0.000     -24.838      -7.076\n",
      "RM             3.4140      0.470      7.266      0.000       2.490       4.338\n",
      "AGE            0.0011      0.015      0.077      0.939      -0.027       0.030\n",
      "DIS           -1.4931      0.233     -6.404      0.000      -1.951      -1.035\n",
      "RAD            0.3644      0.079      4.628      0.000       0.210       0.519\n",
      "TAX           -0.0132      0.004     -2.950      0.003      -0.022      -0.004\n",
      "PTRATIO       -0.9524      0.149     -6.411      0.000      -1.244      -0.660\n",
      "B              0.0117      0.003      3.795      0.000       0.006       0.018\n",
      "LSTAT         -0.5941      0.058    -10.271      0.000      -0.708      -0.480\n",
      "==============================================================================\n",
      "Omnibus:                      134.272   Durbin-Watson:                   2.057\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              542.194\n",
      "Skew:                           1.423   Prob(JB):                    1.84e-118\n",
      "Kurtosis:                       7.911   Cond. No.                     1.51e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.51e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Model statistics\n",
    "model = sm.OLS(Y_train, sm.add_constant(X_train)).fit() #Must add constant for y-intercept\n",
    "Y_pred = model.predict(sm.add_constant(X_test))\n",
    "print_model = model.summary()\n",
    "print(print_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    VIF Factor features\n",
      "0        578.6    const\n",
      "1          1.7     CRIM\n",
      "2          2.4       ZN\n",
      "3          4.1    INDUS\n",
      "4          1.1     CHAS\n",
      "5          4.6      NOX\n",
      "6          1.8       RM\n",
      "7          2.9      AGE\n",
      "8          4.0      DIS\n",
      "9          8.1      RAD\n",
      "10         9.8      TAX\n",
      "11         1.8  PTRATIO\n",
      "12         1.3        B\n",
      "13         2.9    LSTAT\n"
     ]
    }
   ],
   "source": [
    "x_temp = sm.add_constant(X_train)\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(x_temp.values, i) for i in range(x_temp.values.shape[1])]\n",
    "vif[\"features\"] = x_temp.columns\n",
    "print(vif.round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS    TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  296.0     15.3   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  242.0     17.8   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  242.0     17.8   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  222.0     18.7   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  222.0     18.7   \n",
       "\n",
       "        B  LSTAT  \n",
       "0  396.90   4.98  \n",
       "1  396.90   9.14  \n",
       "2  392.83   4.03  \n",
       "3  394.63   2.94  \n",
       "4  396.90   5.33  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ADRESS ISSUES: START WITH ORIGINAL DATASET\n",
    "boston_new=boston_features_df.drop(['RAD'], axis=1)\n",
    "boston_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    VIF Factor features\n",
      "0        532.0    const\n",
      "1          1.6     CRIM\n",
      "2          2.3       ZN\n",
      "3          3.8    INDUS\n",
      "4          1.1     CHAS\n",
      "5          4.6      NOX\n",
      "6          1.8       RM\n",
      "7          2.9      AGE\n",
      "8          4.0      DIS\n",
      "9          3.6      TAX\n",
      "10         1.8  PTRATIO\n",
      "11         1.3        B\n",
      "12         2.9    LSTAT\n"
     ]
    }
   ],
   "source": [
    "#Partition the data\n",
    "\n",
    "X_1 = boston_new\n",
    "Y_1 = boston_target_df\n",
    "\n",
    "X1_train, X1_test, Y1_train, Y1_test = sklearn.model_selection.train_test_split(X_1, Y_1, test_size = 0.20, random_state = 5)\n",
    "\n",
    "# For each X, calculate VIF and save in dataframe\n",
    "x_temp = sm.add_constant(X1_train)\n",
    "\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(x_temp.values, i) for i in range(x_temp.values.shape[1])]\n",
    "vif[\"features\"] = x_temp.columns\n",
    "print(vif.round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   MEDV   R-squared:                       0.724\n",
      "Model:                            OLS   Adj. R-squared:                  0.715\n",
      "Method:                 Least Squares   F-statistic:                     85.46\n",
      "Date:                Mon, 03 May 2021   Prob (F-statistic):          2.63e-101\n",
      "Time:                        21:05:02   Log-Likelihood:                -1212.8\n",
      "No. Observations:                 404   AIC:                             2452.\n",
      "Df Residuals:                     391   BIC:                             2504.\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         30.3242      5.680      5.339      0.000      19.157      41.491\n",
      "CRIM          -0.0911      0.036     -2.518      0.012      -0.162      -0.020\n",
      "ZN             0.0420      0.016      2.607      0.009       0.010       0.074\n",
      "INDUS         -0.0869      0.072     -1.213      0.226      -0.228       0.054\n",
      "CHAS           3.1583      1.009      3.130      0.002       1.174       5.142\n",
      "NOX          -13.2874      4.596     -2.891      0.004     -22.323      -4.252\n",
      "RM             3.7384      0.477      7.845      0.000       2.802       4.675\n",
      "AGE           -0.0035      0.015     -0.234      0.815      -0.033       0.026\n",
      "DIS           -1.5139      0.239     -6.331      0.000      -1.984      -1.044\n",
      "TAX            0.0033      0.003      1.173      0.241      -0.002       0.009\n",
      "PTRATIO       -0.8202      0.150     -5.485      0.000      -1.114      -0.526\n",
      "B              0.0105      0.003      3.329      0.001       0.004       0.017\n",
      "LSTAT         -0.5817      0.059     -9.814      0.000      -0.698      -0.465\n",
      "==============================================================================\n",
      "Omnibus:                      144.710   Durbin-Watson:                   2.078\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              635.723\n",
      "Skew:                           1.513   Prob(JB):                    9.00e-139\n",
      "Kurtosis:                       8.349   Cond. No.                     1.46e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.46e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(Y1_train, sm.add_constant(X1_train)).fit()\n",
    "Y1_pred = model.predict(sm.add_constant(X1_test))\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (Base): 3.2132704958423868\n",
      "\n",
      "Mean Absolute Error (Base): 20.86929218377079\n",
      "\n",
      "Mean Absolute Error (Not collinear): 3.1398352911129916\n",
      "\n",
      "Mean Absolute Error (Not collinear): 20.461656141085523\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn import metrics\n",
    "\n",
    "print('Mean Absolute Error (Base):', metrics.mean_absolute_error(Y_test, Y_pred))  \n",
    "print('')\n",
    "print('Mean Absolute Error (Base):', metrics.mean_squared_error(Y_test, Y_pred))  \n",
    "print('')\n",
    "print('Mean Absolute Error (Not collinear):', metrics.mean_absolute_error(Y_test, Y1_pred))\n",
    "print('')\n",
    "print('Mean Absolute Error (Not collinear):', metrics.mean_squared_error(Y_test, Y1_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
