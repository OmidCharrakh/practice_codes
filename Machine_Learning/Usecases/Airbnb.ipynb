{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import lars_path\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV\n",
    "from sklearn.metrics import r2_score\n",
    "import scipy.stats as stats\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "df=pd.read_csv(\"../data/airbnb.csv\")\n",
    "model_df=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.corr() # Whole correlation matrix\n",
    "model_df.corr()['log_price'] # Check correlations with outcome only\n",
    "sns.heatmap(model_df.corr(), cmap=\"seismic\", annot=True, vmin=-1, vmax=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dummy coding for 'cancellation_policy'\n",
    "model_df = pd.get_dummies(model_df, columns=['cancellation_policy'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(model_df['log_price'], kde=True,);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(model_df['log_price'], plot=plt)\n",
    "print(\"Skewness: %f\" % model_df['log_price'].skew())\n",
    "print(\"Kurtosis: %f\" % model_df['log_price'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature matrix with patsy- this way we get an intercept\n",
    "y_census, X_census = patsy.dmatrices('log_price ~ accommodates + bathrooms + cleaning_fee +\n",
    "                                     host_identity_verified + host_response_rate + instant_bookable + number_of_reviews + \n",
    "                                     review_scores_rating + bedrooms + beds + amenity_count + tourism_mentions + \n",
    "                                     cancellation_policy_moderate + cancellation_policy_strict + property_type_House + \n",
    "                                     property_type_Other + bed_type + room_type_Private_room + room_type_Shared_room + median_home_val + \n",
    "                                     median_income', data=model_df_with_census, return_type=\"dataframe\")\n",
    "\n",
    "#test_size 80-20 split\n",
    "X_train_census, X_test_census, y_train_census, y_test_census = train_test_split(X_census, y_census, test_size=0.2,\n",
    "random_state=42)\n",
    "X_train_census.shape[0] + X_test_census.shape[0] == model_df_with_census.shape[0]\n",
    "\n",
    "# Create model\n",
    "model_census_sm = sm.OLS(y_train_census,X_train_census)\n",
    "\n",
    "# Fit model to training set\n",
    "fit_census = model_census_sm.fit()\n",
    "\n",
    "# Print fit summary\n",
    "fit_census.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for VIFs of each feature, then save to its own DF\n",
    "vif_census = pd.DataFrame()\n",
    "vif_census[“VIF Factor”] = [variance_inflation_factor(X_census.values, i) for i in range(X.shape[1])]\n",
    "vif_census[“features”] = X_census.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use statsmodels to plot the residuals vs the fitted values\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(fit_census.predict(), fit_census.resid); # print resids vs predictions\n",
    "plt.title(\"Residuals plot from OLS Model\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.savefig('LR_Residual_Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scale the data\n",
    "std = StandardScaler()\n",
    "std.fit(X_train_census.values) # only std.fit on train set\n",
    "X_tr_census = std.transform(X_train_census.values)\n",
    "X_te_census = std.transform(X_test_census.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cross validation, find the best alpha, refit the model on all the data with that alpha\n",
    "alphavec = 10**np.linspace(-2,2,200)\n",
    "lasso_model_census = LassoCV(alphas = alphavec, cv=5)\n",
    "lasso_model_census.fit(X_tr_census, y_train_census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print feature name zipped with its beta\n",
    "lasso_betas = list(zip(X_train_census.columns,\n",
    "lasso_model_census.coef_))\n",
    "# R2 of Training set\n",
    "lasso_model_census.score(X_tr_census,y_train_census)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict model on test data\n",
    "y_census_pred = lasso_model_census.predict(X_te_census)\n",
    "# R2 of test set using this model\n",
    "r2_score(y_test_census, y_census_pred)\n",
    "#Mean Absolute Error (MAE)\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_pred - y_true))\n",
    "mae(y_test_census, y_census_pred)\n",
    "# Plot\n",
    "plt.scatter(y_test_census, y_census_pred)\n",
    "plt.plot([0,10],[0,10],color='red')\n",
    "plt.grid(True)\n",
    "plt.title('Predicted vs. Actual Rental Price (log) with LASSO CV')\n",
    "plt.ylabel('Rental Price (log) Predicted')\n",
    "plt.xlabel('Rental Price (log) Actual');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Computing regularization path using the LARS ...\")\n",
    "alphas, _, coefs = lars_path(X_tr_census, y_train_census, method='lasso')\n",
    "# # plotting the LARS path\n",
    "xx = np.sum(np.abs(coefs.T), axis=1)\n",
    "xx /= xx[-1]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(xx, coefs.T)\n",
    "ymin, ymax = plt.ylim()\n",
    "plt.vlines(xx, ymin, ymax, linestyle='dashed')\n",
    "plt.xlabel('|coef| / max|coef|')\n",
    "plt.ylabel('Coefficients')\n",
    "plt.title('LASSO Path')\n",
    "plt.axis('tight')\n",
    "plt.legend(X_train_census.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
